{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting backports.tarfile==1.2.0 (from -r requirements2.txt (line 1))\n",
      "  Using cached backports.tarfile-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting chromadb==0.5.5 (from -r requirements2.txt (line 2))\n",
      "  Using cached chromadb-0.5.5-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting datasets==2.20.0 (from -r requirements2.txt (line 3))\n",
      "  Using cached datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting gradio==4.41.0 (from -r requirements2.txt (line 4))\n",
      "  Using cached gradio-4.41.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting h2==4.1.0 (from -r requirements2.txt (line 5))\n",
      "  Using cached h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting httptools==0.6.1 (from -r requirements2.txt (line 6))\n",
      "  Using cached httptools-0.6.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: ipykernel==6.29.5 in ./letest_env/lib/python3.12/site-packages (from -r requirements2.txt (line 7)) (6.29.5)\n",
      "Collecting jaraco.text==3.12.1 (from -r requirements2.txt (line 8))\n",
      "  Using cached jaraco.text-3.12.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting langchain-community==0.2.12 (from -r requirements2.txt (line 9))\n",
      "  Using cached langchain_community-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting ollama-haystack==0.0.7 (from -r requirements2.txt (line 10))\n",
      "  Using cached ollama_haystack-0.0.7-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting ordered-set==4.1.0 (from -r requirements2.txt (line 11))\n",
      "  Using cached ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pip-chill==1.0.3 (from -r requirements2.txt (line 12))\n",
      "  Using cached pip_chill-1.0.3-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting pypdf==4.3.1 (from -r requirements2.txt (line 13))\n",
      "  Using cached pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting python-dotenv==1.0.1 (from -r requirements2.txt (line 14))\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting qdrant-haystack==4.1.2 (from -r requirements2.txt (line 15))\n",
      "  Using cached qdrant_haystack-4.1.2-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting sentence-transformers==3.0.1 (from -r requirements2.txt (line 16))\n",
      "  Using cached sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting tomli==2.0.1 (from -r requirements2.txt (line 17))\n",
      "  Using cached tomli-2.0.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting uvloop==0.19.0 (from -r requirements2.txt (line 18))\n",
      "  Using cached uvloop-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles==0.23.0 (from -r requirements2.txt (line 19))\n",
      "  Using cached watchfiles-0.23.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting build>=1.0.3 (from chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached build-1.2.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting pydantic>=1.9 (from chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached chroma_hnswlib-0.7.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
      "Collecting fastapi>=0.95.2 (from chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached fastapi-0.112.1-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting numpy<2.0.0,>=1.22.5 (from chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting posthog>=2.4.0 (from chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting typing-extensions>=4.5.0 (from chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached onnxruntime-1.19.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached opentelemetry_api-1.26.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.47b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached opentelemetry_sdk-1.26.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached tokenizers-0.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached PyPika-0.48.9-py2.py3-none-any.whl\n",
      "Collecting tqdm>=4.65.0 (from chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting overrides>=7.3.1 (from chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached importlib_resources-6.4.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached grpcio-1.65.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached typer-0.12.4-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached kubernetes-30.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting tenacity>=8.2.3 (from chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting PyYAML>=6.0.0 (from chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached mmh3-4.1.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached orjson-3.10.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "Collecting httpx>=0.27.0 (from chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting filelock (from datasets==2.20.0->-r requirements2.txt (line 3))\n",
      "  Using cached filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets==2.20.0->-r requirements2.txt (line 3))\n",
      "  Using cached pyarrow-17.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting pyarrow-hotfix (from datasets==2.20.0->-r requirements2.txt (line 3))\n",
      "  Using cached pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets==2.20.0->-r requirements2.txt (line 3))\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets==2.20.0->-r requirements2.txt (line 3))\n",
      "  Using cached pandas-2.2.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting requests>=2.32.2 (from datasets==2.20.0->-r requirements2.txt (line 3))\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting xxhash (from datasets==2.20.0->-r requirements2.txt (line 3))\n",
      "  Using cached xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets==2.20.0->-r requirements2.txt (line 3))\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.5.0,>=2023.1.0 (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets==2.20.0->-r requirements2.txt (line 3))\n",
      "  Using cached fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets==2.20.0->-r requirements2.txt (line 3))\n",
      "  Using cached aiohttp-3.10.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting huggingface-hub>=0.21.2 (from datasets==2.20.0->-r requirements2.txt (line 3))\n",
      "  Using cached huggingface_hub-0.24.6-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in ./letest_env/lib/python3.12/site-packages (from datasets==2.20.0->-r requirements2.txt (line 3)) (24.1)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio==4.41.0->-r requirements2.txt (line 4))\n",
      "  Using cached aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting anyio<5.0,>=3.0 (from gradio==4.41.0->-r requirements2.txt (line 4))\n",
      "  Using cached anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting ffmpy (from gradio==4.41.0->-r requirements2.txt (line 4))\n",
      "  Using cached ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==1.3.0 (from gradio==4.41.0->-r requirements2.txt (line 4))\n",
      "  Using cached gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jinja2<4.0 (from gradio==4.41.0->-r requirements2.txt (line 4))\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting markupsafe~=2.0 (from gradio==4.41.0->-r requirements2.txt (line 4))\n",
      "  Using cached MarkupSafe-2.1.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting matplotlib~=3.0 (from gradio==4.41.0->-r requirements2.txt (line 4))\n",
      "  Using cached matplotlib-3.9.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting pillow<11.0,>=8.0 (from gradio==4.41.0->-r requirements2.txt (line 4))\n",
      "  Using cached pillow-10.4.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting pydub (from gradio==4.41.0->-r requirements2.txt (line 4))\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.9 (from gradio==4.41.0->-r requirements2.txt (line 4))\n",
      "  Using cached python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting ruff>=0.2.2 (from gradio==4.41.0->-r requirements2.txt (line 4))\n",
      "  Using cached ruff-0.6.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio==4.41.0->-r requirements2.txt (line 4))\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio==4.41.0->-r requirements2.txt (line 4))\n",
      "  Using cached tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting urllib3~=2.0 (from gradio==4.41.0->-r requirements2.txt (line 4))\n",
      "  Using cached urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting hyperframe<7,>=6.0 (from h2==4.1.0->-r requirements2.txt (line 5))\n",
      "  Using cached hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting hpack<5,>=4.0 (from h2==4.1.0->-r requirements2.txt (line 5))\n",
      "  Using cached hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: comm>=0.1.1 in ./letest_env/lib/python3.12/site-packages (from ipykernel==6.29.5->-r requirements2.txt (line 7)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./letest_env/lib/python3.12/site-packages (from ipykernel==6.29.5->-r requirements2.txt (line 7)) (1.8.5)\n",
      "Requirement already satisfied: ipython>=7.23.1 in ./letest_env/lib/python3.12/site-packages (from ipykernel==6.29.5->-r requirements2.txt (line 7)) (8.26.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in ./letest_env/lib/python3.12/site-packages (from ipykernel==6.29.5->-r requirements2.txt (line 7)) (8.6.2)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./letest_env/lib/python3.12/site-packages (from ipykernel==6.29.5->-r requirements2.txt (line 7)) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./letest_env/lib/python3.12/site-packages (from ipykernel==6.29.5->-r requirements2.txt (line 7)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in ./letest_env/lib/python3.12/site-packages (from ipykernel==6.29.5->-r requirements2.txt (line 7)) (1.6.0)\n",
      "Requirement already satisfied: psutil in ./letest_env/lib/python3.12/site-packages (from ipykernel==6.29.5->-r requirements2.txt (line 7)) (6.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in ./letest_env/lib/python3.12/site-packages (from ipykernel==6.29.5->-r requirements2.txt (line 7)) (26.1.1)\n",
      "Requirement already satisfied: tornado>=6.1 in ./letest_env/lib/python3.12/site-packages (from ipykernel==6.29.5->-r requirements2.txt (line 7)) (6.4.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in ./letest_env/lib/python3.12/site-packages (from ipykernel==6.29.5->-r requirements2.txt (line 7)) (5.14.3)\n",
      "Collecting jaraco.functools (from jaraco.text==3.12.1->-r requirements2.txt (line 8))\n",
      "  Using cached jaraco.functools-4.0.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting jaraco.context>=4.1 (from jaraco.text==3.12.1->-r requirements2.txt (line 8))\n",
      "  Using cached jaraco.context-6.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting autocommand (from jaraco.text==3.12.1->-r requirements2.txt (line 8))\n",
      "  Using cached autocommand-2.2.2-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting inflect (from jaraco.text==3.12.1->-r requirements2.txt (line 8))\n",
      "  Using cached inflect-7.3.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting more-itertools (from jaraco.text==3.12.1->-r requirements2.txt (line 8))\n",
      "  Using cached more_itertools-10.4.0-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain-community==0.2.12->-r requirements2.txt (line 9))\n",
      "  Using cached SQLAlchemy-2.0.32-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community==0.2.12->-r requirements2.txt (line 9))\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain<0.3.0,>=0.2.13 (from langchain-community==0.2.12->-r requirements2.txt (line 9))\n",
      "  Using cached langchain-0.2.14-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-core<0.3.0,>=0.2.30 (from langchain-community==0.2.12->-r requirements2.txt (line 9))\n",
      "  Using cached langchain_core-0.2.33-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.0 (from langchain-community==0.2.12->-r requirements2.txt (line 9))\n",
      "  Using cached langsmith-0.1.100-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tenacity>=8.2.3 (from chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting haystack-ai (from ollama-haystack==0.0.7->-r requirements2.txt (line 10))\n",
      "  Using cached haystack_ai-2.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting qdrant-client>=1.10.0 (from qdrant-haystack==4.1.2->-r requirements2.txt (line 15))\n",
      "  Using cached qdrant_client-1.11.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.34.0 (from sentence-transformers==3.0.1->-r requirements2.txt (line 16))\n",
      "  Using cached transformers-4.44.1-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers==3.0.1->-r requirements2.txt (line 16))\n",
      "  Using cached torch-2.4.0-cp312-cp312-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting scikit-learn (from sentence-transformers==3.0.1->-r requirements2.txt (line 16))\n",
      "  Using cached scikit_learn-1.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting scipy (from sentence-transformers==3.0.1->-r requirements2.txt (line 16))\n",
      "  Using cached scipy-1.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio==4.41.0->-r requirements2.txt (line 4))\n",
      "  Using cached websockets-12.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets==2.20.0->-r requirements2.txt (line 3))\n",
      "  Using cached aiohappyeyeballs-2.4.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets==2.20.0->-r requirements2.txt (line 3))\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets==2.20.0->-r requirements2.txt (line 3))\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets==2.20.0->-r requirements2.txt (line 3))\n",
      "  Using cached frozenlist-1.4.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets==2.20.0->-r requirements2.txt (line 3))\n",
      "  Using cached multidict-6.0.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets==2.20.0->-r requirements2.txt (line 3))\n",
      "  Using cached yarl-1.9.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting idna>=2.8 (from anyio<5.0,>=3.0->gradio==4.41.0->-r requirements2.txt (line 4))\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting sniffio>=1.1 (from anyio<5.0,>=3.0->gradio==4.41.0->-r requirements2.txt (line 4))\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached pyproject_hooks-1.1.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.12->-r requirements2.txt (line 9))\n",
      "  Using cached marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.12->-r requirements2.txt (line 9))\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting starlette<0.39.0,>=0.37.2 (from fastapi>=0.95.2->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached starlette-0.38.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting certifi (from httpx>=0.27.0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.27.0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.27.0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: decorator in ./letest_env/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.5->-r requirements2.txt (line 7)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./letest_env/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.5->-r requirements2.txt (line 7)) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in ./letest_env/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.5->-r requirements2.txt (line 7)) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./letest_env/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.5->-r requirements2.txt (line 7)) (2.18.0)\n",
      "Requirement already satisfied: stack-data in ./letest_env/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.5->-r requirements2.txt (line 7)) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in ./letest_env/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.5->-r requirements2.txt (line 7)) (4.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./letest_env/lib/python3.12/site-packages (from jupyter-client>=6.1.12->ipykernel==6.29.5->-r requirements2.txt (line 7)) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./letest_env/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel==6.29.5->-r requirements2.txt (line 7)) (4.2.2)\n",
      "Requirement already satisfied: six>=1.9.0 in ./letest_env/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.5.5->-r requirements2.txt (line 2)) (1.16.0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached google_auth-2.34.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.13->langchain-community==0.2.12->-r requirements2.txt (line 9))\n",
      "  Using cached langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.30->langchain-community==0.2.12->-r requirements2.txt (line 9))\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib~=3.0->gradio==4.41.0->-r requirements2.txt (line 4))\n",
      "  Using cached contourpy-1.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib~=3.0->gradio==4.41.0->-r requirements2.txt (line 4))\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib~=3.0->gradio==4.41.0->-r requirements2.txt (line 4))\n",
      "  Using cached fonttools-4.53.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (162 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib~=3.0->gradio==4.41.0->-r requirements2.txt (line 4))\n",
      "  Using cached kiwisolver-1.4.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib~=3.0->gradio==4.41.0->-r requirements2.txt (line 4))\n",
      "  Using cached pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached protobuf-5.27.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached sympy-1.13.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting importlib-metadata<=8.0.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached importlib_metadata-8.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached googleapis_common_protos-1.63.2-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached opentelemetry_proto-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.47b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached opentelemetry_instrumentation-0.47b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-util-http==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached opentelemetry_util_http-0.47b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting setuptools>=16.0 (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached setuptools-73.0.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached wrapt-1.16.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets==2.20.0->-r requirements2.txt (line 3))\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets==2.20.0->-r requirements2.txt (line 3))\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic>=1.9->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.20.1 (from pydantic>=1.9->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached pydantic_core-2.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting grpcio-tools>=1.41.0 (from qdrant-client>=1.10.0->qdrant-haystack==4.1.2->-r requirements2.txt (line 15))\n",
      "  Using cached grpcio_tools-1.65.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client>=1.10.0->qdrant-haystack==4.1.2->-r requirements2.txt (line 15))\n",
      "  Using cached portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.32.2->datasets==2.20.0->-r requirements2.txt (line 3))\n",
      "  Using cached charset_normalizer-3.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain-community==0.2.12->-r requirements2.txt (line 9))\n",
      "  Using cached greenlet-3.0.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers==3.0.1->-r requirements2.txt (line 16))\n",
      "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers==3.0.1->-r requirements2.txt (line 16))\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers==3.0.1->-r requirements2.txt (line 16))\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers==3.0.1->-r requirements2.txt (line 16))\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers==3.0.1->-r requirements2.txt (line 16))\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers==3.0.1->-r requirements2.txt (line 16))\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers==3.0.1->-r requirements2.txt (line 16))\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers==3.0.1->-r requirements2.txt (line 16))\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers==3.0.1->-r requirements2.txt (line 16))\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers==3.0.1->-r requirements2.txt (line 16))\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.11.0->sentence-transformers==3.0.1->-r requirements2.txt (line 16))\n",
      "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers==3.0.1->-r requirements2.txt (line 16))\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.0.0 (from torch>=1.11.0->sentence-transformers==3.0.1->-r requirements2.txt (line 16))\n",
      "  Using cached triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers==3.0.1->-r requirements2.txt (line 16))\n",
      "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.34.0->sentence-transformers==3.0.1->-r requirements2.txt (line 16))\n",
      "  Using cached regex-2024.7.24-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.34.0->sentence-transformers==3.0.1->-r requirements2.txt (line 16))\n",
      "  Using cached safetensors-0.4.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting click>=8.0.0 (from typer>=0.9.0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer>=0.9.0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting haystack-experimental (from haystack-ai->ollama-haystack==0.0.7->-r requirements2.txt (line 10))\n",
      "  Using cached haystack_experimental-0.1.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting lazy-imports (from haystack-ai->ollama-haystack==0.0.7->-r requirements2.txt (line 10))\n",
      "  Using cached lazy_imports-0.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting openai>=1.1.0 (from haystack-ai->ollama-haystack==0.0.7->-r requirements2.txt (line 10))\n",
      "  Using cached openai-1.42.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting typeguard>=4.0.1 (from inflect->jaraco.text==3.12.1->-r requirements2.txt (line 8))\n",
      "  Using cached typeguard-4.3.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers==3.0.1->-r requirements2.txt (line 16))\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers==3.0.1->-r requirements2.txt (line 16))\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "INFO: pip is looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-tools>=1.41.0 (from qdrant-client>=1.10.0->qdrant-haystack==4.1.2->-r requirements2.txt (line 15))\n",
      "  Using cached grpcio_tools-1.65.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Using cached grpcio_tools-1.65.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Using cached grpcio_tools-1.65.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Using cached grpcio_tools-1.64.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Using cached grpcio_tools-1.64.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Using cached grpcio_tools-1.64.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Using cached grpcio_tools-1.63.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "INFO: pip is still looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached grpcio_tools-1.63.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Using cached grpcio_tools-1.62.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Collecting zipp>=0.5 (from importlib-metadata<=8.0.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached zipp-3.20.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./letest_env/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel==6.29.5->-r requirements2.txt (line 7)) (0.8.4)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.30->langchain-community==0.2.12->-r requirements2.txt (line 9))\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.1.0->haystack-ai->ollama-haystack==0.0.7->-r requirements2.txt (line 10))\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.1.0->haystack-ai->ollama-haystack==0.0.7->-r requirements2.txt (line 10))\n",
      "  Using cached jiter-0.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./letest_env/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel==6.29.5->-r requirements2.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./letest_env/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel==6.29.5->-r requirements2.txt (line 7)) (0.2.13)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer>=0.9.0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.12->-r requirements2.txt (line 9))\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./letest_env/lib/python3.12/site-packages (from stack-data->ipython>=7.23.1->ipykernel==6.29.5->-r requirements2.txt (line 7)) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./letest_env/lib/python3.12/site-packages (from stack-data->ipython>=7.23.1->ipykernel==6.29.5->-r requirements2.txt (line 7)) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in ./letest_env/lib/python3.12/site-packages (from stack-data->ipython>=7.23.1->ipykernel==6.29.5->-r requirements2.txt (line 7)) (0.2.3)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.5->-r requirements2.txt (line 2))\n",
      "  Using cached pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Using cached backports.tarfile-1.2.0-py3-none-any.whl (30 kB)\n",
      "Using cached chromadb-0.5.5-py3-none-any.whl (584 kB)\n",
      "Using cached datasets-2.20.0-py3-none-any.whl (547 kB)\n",
      "Using cached gradio-4.41.0-py3-none-any.whl (12.6 MB)\n",
      "Using cached h2-4.1.0-py3-none-any.whl (57 kB)\n",
      "Using cached httptools-0.6.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (344 kB)\n",
      "Using cached jaraco.text-3.12.1-py3-none-any.whl (11 kB)\n",
      "Using cached langchain_community-0.2.12-py3-none-any.whl (2.3 MB)\n",
      "Using cached ollama_haystack-0.0.7-py3-none-any.whl (15 kB)\n",
      "Using cached ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Using cached pip_chill-1.0.3-py2.py3-none-any.whl (6.9 kB)\n",
      "Using cached pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached qdrant_haystack-4.1.2-py3-none-any.whl (22 kB)\n",
      "Using cached sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
      "Using cached tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Using cached uvloop-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n",
      "Using cached watchfiles-0.23.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\n",
      "Using cached chroma_hnswlib-0.7.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "Using cached gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
      "Using cached tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Using cached aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiohttp-3.10.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Using cached anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "Using cached bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl (273 kB)\n",
      "Using cached build-1.2.1-py3-none-any.whl (21 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fastapi-0.112.1-py3-none-any.whl (93 kB)\n",
      "Using cached fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "Using cached grpcio-1.65.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
      "Using cached hpack-4.0.0-py3-none-any.whl (32 kB)\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Using cached huggingface_hub-0.24.6-py3-none-any.whl (417 kB)\n",
      "Using cached hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
      "Using cached importlib_resources-6.4.3-py3-none-any.whl (35 kB)\n",
      "Using cached jaraco.context-6.0.1-py3-none-any.whl (6.8 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Using cached langchain-0.2.14-py3-none-any.whl (997 kB)\n",
      "Using cached langchain_core-0.2.33-py3-none-any.whl (391 kB)\n",
      "Using cached langsmith-0.1.100-py3-none-any.whl (148 kB)\n",
      "Using cached MarkupSafe-2.1.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
      "Using cached matplotlib-3.9.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "Using cached mmh3-4.1.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (68 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "Using cached onnxruntime-1.19.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
      "Using cached opentelemetry_api-1.26.0-py3-none-any.whl (61 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl (17 kB)\n",
      "Using cached opentelemetry_proto-1.26.0-py3-none-any.whl (52 kB)\n",
      "Using cached opentelemetry_instrumentation_fastapi-0.47b0-py3-none-any.whl (11 kB)\n",
      "Using cached opentelemetry_instrumentation-0.47b0-py3-none-any.whl (29 kB)\n",
      "Using cached opentelemetry_instrumentation_asgi-0.47b0-py3-none-any.whl (15 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl (138 kB)\n",
      "Using cached opentelemetry_util_http-0.47b0-py3-none-any.whl (6.9 kB)\n",
      "Using cached opentelemetry_sdk-1.26.0-py3-none-any.whl (109 kB)\n",
      "Using cached orjson-3.10.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Using cached pandas-2.2.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "Using cached pillow-10.4.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Using cached posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
      "Using cached pyarrow-17.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (39.9 MB)\n",
      "Using cached pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "Using cached pydantic_core-2.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "Using cached python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (767 kB)\n",
      "Using cached qdrant_client-1.11.0-py3-none-any.whl (258 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached ruff-0.6.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Using cached SQLAlchemy-2.0.32-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "Using cached tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Using cached torch-2.4.0-cp312-cp312-manylinux1_x86_64.whl (797.2 MB)\n",
      "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Using cached triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.5 MB)\n",
      "Using cached tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Using cached transformers-4.44.1-py3-none-any.whl (9.5 MB)\n",
      "Using cached tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Using cached typer-0.12.4-py3-none-any.whl (47 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
      "Using cached uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
      "Using cached autocommand-2.2.2-py3-none-any.whl (19 kB)\n",
      "Using cached ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
      "Using cached filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Using cached haystack_ai-2.4.0-py3-none-any.whl (350 kB)\n",
      "Using cached inflect-7.3.1-py3-none-any.whl (34 kB)\n",
      "Using cached more_itertools-10.4.0-py3-none-any.whl (60 kB)\n",
      "Using cached jaraco.functools-4.0.2-py3-none-any.whl (9.9 kB)\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Using cached pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Using cached scikit_learn-1.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "Using cached scipy-1.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.8 MB)\n",
      "Using cached xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Using cached aiohappyeyeballs-2.4.0-py3-none-any.whl (12 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached contourpy-1.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (309 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached fonttools-4.53.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "Using cached frozenlist-1.4.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
      "Using cached google_auth-2.34.0-py2.py3-none-any.whl (200 kB)\n",
      "Using cached googleapis_common_protos-1.63.2-py2.py3-none-any.whl (220 kB)\n",
      "Using cached greenlet-3.0.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (625 kB)\n",
      "Using cached grpcio_tools-1.62.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached importlib_metadata-8.0.0-py3-none-any.whl (24 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached kiwisolver-1.4.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "Using cached langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
      "Using cached marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
      "Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Using cached multidict-6.0.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Using cached openai-1.42.0-py3-none-any.whl (362 kB)\n",
      "Using cached portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Using cached protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached regex-2024.7.24-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (790 kB)\n",
      "Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Using cached safetensors-0.4.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (434 kB)\n",
      "Using cached setuptools-73.0.1-py3-none-any.whl (2.3 MB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached starlette-0.38.2-py3-none-any.whl (72 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached typeguard-4.3.0-py3-none-any.whl (35 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Using cached websockets-12.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n",
      "Using cached yarl-1.9.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (322 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached haystack_experimental-0.1.1-py3-none-any.whl (41 kB)\n",
      "Using cached lazy_imports-0.3.1-py3-none-any.whl (12 kB)\n",
      "Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Using cached pyproject_hooks-1.1.0-py3-none-any.whl (9.2 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached sympy-1.13.2-py3-none-any.whl (6.2 MB)\n",
      "Using cached asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Using cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached jiter-0.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached wrapt-1.16.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (87 kB)\n",
      "Using cached zipp-3.20.0-py3-none-any.whl (9.4 kB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade pip\n",
    "# ! pip install haystack \n",
    "# !pip install haystack-ai\n",
    "# !pip install farm-haystack[colab,inference]\n",
    "# !pip3.10 uninstall pydantic urllib3\n",
    "# !pip install farm-haystack[colab,preprocessing,elasticsearch,inference]\n",
    "!pip install -r requirements2.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "PydanticSchemaGenerationError",
     "evalue": "Unable to generate pydantic-core schema for <class 'pandas.core.frame.DataFrame'>. Set `arbitrary_types_allowed=True` in the model_config to ignore this error or implement `__get_pydantic_core_schema__` on your type to fully support it.\n\nIf you got this error by calling handler(<some type>) within `__get_pydantic_core_schema__` then you likely need to call `handler.generate_schema(<some type>)` since we do not call `__get_pydantic_core_schema__` on `<some type>` otherwise to avoid infinite recursion.\n\nFor further information visit https://errors.pydantic.dev/2.8/u/schema-for-unknown-type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPydanticSchemaGenerationError\u001b[0m             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhaystack\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhaystack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_stores\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DuplicatePolicy\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhaystack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompt_builder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptBuilder\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/haystack/__init__.py:10\u001b[0m\n\u001b[1;32m      6\u001b[0m __version__: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(metadata\u001b[38;5;241m.\u001b[39mversion(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfarm-haystack\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhaystack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msilenceable_tqdm\u001b[39;00m  \u001b[38;5;66;03m# Needs to be imported first to wrap TQDM for all following modules\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhaystack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Document, Answer, Label, MultiLabel, Span, EvaluationResult, TableCell\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhaystack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnodes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseComponent\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhaystack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipelines\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/haystack/schema.py:41\u001b[0m\n\u001b[1;32m     36\u001b[0m FilterType \u001b[38;5;241m=\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], List[Any], \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mbool\u001b[39m]]\n\u001b[1;32m     38\u001b[0m LABEL_DATETIME_FORMAT: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;129;43m@dataclass\u001b[39;49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mDocument\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mUnion\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/dataclasses.py:258\u001b[0m, in \u001b[0;36mdataclass\u001b[0;34m(_cls, init, repr, eq, order, unsafe_hash, frozen, config, validate_on_init, kw_only, slots)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cls \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m create_dataclass\n\u001b[0;32m--> 258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_dataclass\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_cls\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/dataclasses.py:249\u001b[0m, in \u001b[0;36mdataclass.<locals>.create_dataclass\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m \u001b[38;5;241m=\u001b[39m original_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;241m=\u001b[39m original_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\n\u001b[0;32m--> 249\u001b[0m pydantic_complete \u001b[38;5;241m=\u001b[39m \u001b[43m_pydantic_dataclasses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete_dataclass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_wrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes_namespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    251\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_complete__ \u001b[38;5;241m=\u001b[39m pydantic_complete  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_dataclasses.py:160\u001b[0m, in \u001b[0;36mcomplete_dataclass\u001b[0;34m(cls, config_wrapper, raise_errors, types_namespace)\u001b[0m\n\u001b[1;32m    151\u001b[0m         schema \u001b[38;5;241m=\u001b[39m get_core_schema(\n\u001b[1;32m    152\u001b[0m             \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m    153\u001b[0m             CallbackGetCoreSchemaHandler(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    157\u001b[0m             ),\n\u001b[1;32m    158\u001b[0m         )\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m         schema \u001b[38;5;241m=\u001b[39m \u001b[43mgen_schema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_dunder_get_core_schema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PydanticUndefinedAnnotation \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raise_errors:\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:512\u001b[0m, in \u001b[0;36mGenerateSchema.generate_schema\u001b[0;34m(self, obj, from_dunder_get_core_schema)\u001b[0m\n\u001b[1;32m    509\u001b[0m         schema \u001b[38;5;241m=\u001b[39m from_property\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 512\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_schema_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    514\u001b[0m metadata_js_function \u001b[38;5;241m=\u001b[39m _extract_get_pydantic_json_schema(obj, schema)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadata_js_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:789\u001b[0m, in \u001b[0;36mGenerateSchema._generate_schema_inner\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, PydanticRecursiveRef):\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m core_schema\u001b[38;5;241m.\u001b[39mdefinition_reference_schema(schema_ref\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mtype_ref)\n\u001b[0;32m--> 789\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:863\u001b[0m, in \u001b[0;36mGenerateSchema.match_type\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_enum_core_schema(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config_wrapper\u001b[38;5;241m.\u001b[39mconfig_dict)\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _typing_extra\u001b[38;5;241m.\u001b[39mis_dataclass(obj):\n\u001b[0;32m--> 863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataclass_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    864\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_prepare_pydantic_annotations_for_known_type(obj, ())\n\u001b[1;32m    865\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:1619\u001b[0m, in \u001b[0;36mGenerateSchema._dataclass_schema\u001b[0;34m(self, dataclass, origin)\u001b[0m\n\u001b[1;32m   1616\u001b[0m decorators \u001b[38;5;241m=\u001b[39m dataclass\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__pydantic_decorators__\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m DecoratorInfos\u001b[38;5;241m.\u001b[39mbuild(dataclass)\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;66;03m# Move kw_only=False args to the start of the list, as this is how vanilla dataclasses work.\u001b[39;00m\n\u001b[1;32m   1618\u001b[0m \u001b[38;5;66;03m# Note that when kw_only is missing or None, it is treated as equivalent to kw_only=True\u001b[39;00m\n\u001b[0;32m-> 1619\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1620\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_dc_field_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecorators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkw_only\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1622\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1623\u001b[0m has_post_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mhasattr\u001b[39m(dataclass, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__post_init__\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1624\u001b[0m has_slots \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mhasattr\u001b[39m(dataclass, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__slots__\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:1620\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1616\u001b[0m decorators \u001b[38;5;241m=\u001b[39m dataclass\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__pydantic_decorators__\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m DecoratorInfos\u001b[38;5;241m.\u001b[39mbuild(dataclass)\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;66;03m# Move kw_only=False args to the start of the list, as this is how vanilla dataclasses work.\u001b[39;00m\n\u001b[1;32m   1618\u001b[0m \u001b[38;5;66;03m# Note that when kw_only is missing or None, it is treated as equivalent to kw_only=True\u001b[39;00m\n\u001b[1;32m   1619\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\n\u001b[0;32m-> 1620\u001b[0m     (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_dc_field_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecorators\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m fields\u001b[38;5;241m.\u001b[39mitems()),\n\u001b[1;32m   1621\u001b[0m     key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m a: a\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkw_only\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1622\u001b[0m )\n\u001b[1;32m   1623\u001b[0m has_post_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mhasattr\u001b[39m(dataclass, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__post_init__\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1624\u001b[0m has_slots \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mhasattr\u001b[39m(dataclass, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__slots__\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:964\u001b[0m, in \u001b[0;36mGenerateSchema._generate_dc_field_schema\u001b[0;34m(self, name, field_info, decorators)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_dc_field_schema\u001b[39m(\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    959\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    960\u001b[0m     field_info: FieldInfo,\n\u001b[1;32m    961\u001b[0m     decorators: DecoratorInfos,\n\u001b[1;32m    962\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m core_schema\u001b[38;5;241m.\u001b[39mDataclassField:\n\u001b[1;32m    963\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prepare a DataclassField to represent the parameter/field, of a dataclass.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 964\u001b[0m     common_field \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_common_field_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfield_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecorators\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m core_schema\u001b[38;5;241m.\u001b[39mdataclass_field(\n\u001b[1;32m    966\u001b[0m         name,\n\u001b[1;32m    967\u001b[0m         common_field[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mschema\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    975\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mcommon_field[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    976\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:1134\u001b[0m, in \u001b[0;36mGenerateSchema._common_field_schema\u001b[0;34m(self, name, field_info, decorators)\u001b[0m\n\u001b[1;32m   1132\u001b[0m         schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_annotations(source_type, annotations, transform_inner_schema\u001b[38;5;241m=\u001b[39mset_discriminator)\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m         schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_annotations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[43m            \u001b[49m\u001b[43msource_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[43m            \u001b[49m\u001b[43mannotations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;66;03m# This V1 compatibility shim should eventually be removed\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;66;03m# push down any `each_item=True` validators\u001b[39;00m\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;66;03m# note that this won't work for any Annotated types that get wrapped by a function validator\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;66;03m# but that's okay because that didn't exist in V1\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m this_field_validators \u001b[38;5;241m=\u001b[39m filter_field_decorator_info_by_field(decorators\u001b[38;5;241m.\u001b[39mvalidators\u001b[38;5;241m.\u001b[39mvalues(), name)\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:1890\u001b[0m, in \u001b[0;36mGenerateSchema._apply_annotations\u001b[0;34m(self, source_type, annotations, transform_inner_schema)\u001b[0m\n\u001b[1;32m   1885\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1886\u001b[0m     get_inner_schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_wrapped_inner_schema(\n\u001b[1;32m   1887\u001b[0m         get_inner_schema, annotation, pydantic_js_annotation_functions\n\u001b[1;32m   1888\u001b[0m     )\n\u001b[0;32m-> 1890\u001b[0m schema \u001b[38;5;241m=\u001b[39m \u001b[43mget_inner_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pydantic_js_annotation_functions:\n\u001b[1;32m   1892\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m CoreMetadataHandler(schema)\u001b[38;5;241m.\u001b[39mmetadata\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_schema_generation_shared.py:83\u001b[0m, in \u001b[0;36mCallbackGetCoreSchemaHandler.__call__\u001b[0;34m(self, source_type)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, source_type: Any, \u001b[38;5;241m/\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m core_schema\u001b[38;5;241m.\u001b[39mCoreSchema:\n\u001b[0;32m---> 83\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     ref \u001b[38;5;241m=\u001b[39m schema\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mref\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ref_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto-def\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:1871\u001b[0m, in \u001b[0;36mGenerateSchema._apply_annotations.<locals>.inner_handler\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1869\u001b[0m from_property \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_schema_from_property(obj, source_type)\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_property \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1871\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_schema_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1872\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1873\u001b[0m     schema \u001b[38;5;241m=\u001b[39m from_property\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:789\u001b[0m, in \u001b[0;36mGenerateSchema._generate_schema_inner\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, PydanticRecursiveRef):\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m core_schema\u001b[38;5;241m.\u001b[39mdefinition_reference_schema(schema_ref\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mtype_ref)\n\u001b[0;32m--> 789\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:871\u001b[0m, in \u001b[0;36mGenerateSchema.match_type\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    869\u001b[0m origin \u001b[38;5;241m=\u001b[39m get_origin(obj)\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m origin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 871\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_match_generic_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arbitrary_types:\n\u001b[1;32m    874\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arbitrary_type_schema(obj)\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:895\u001b[0m, in \u001b[0;36mGenerateSchema._match_generic_type\u001b[0;34m(self, obj, origin)\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m from_property\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _typing_extra\u001b[38;5;241m.\u001b[39morigin_is_union(origin):\n\u001b[0;32m--> 895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_union_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m origin \u001b[38;5;129;01min\u001b[39;00m TUPLE_TYPES:\n\u001b[1;32m    897\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tuple_schema(obj)\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:1207\u001b[0m, in \u001b[0;36mGenerateSchema._union_schema\u001b[0;34m(self, union_type)\u001b[0m\n\u001b[1;32m   1205\u001b[0m         nullable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1206\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1207\u001b[0m         choices\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(choices) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1210\u001b[0m     s \u001b[38;5;241m=\u001b[39m choices[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:512\u001b[0m, in \u001b[0;36mGenerateSchema.generate_schema\u001b[0;34m(self, obj, from_dunder_get_core_schema)\u001b[0m\n\u001b[1;32m    509\u001b[0m         schema \u001b[38;5;241m=\u001b[39m from_property\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 512\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_schema_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    514\u001b[0m metadata_js_function \u001b[38;5;241m=\u001b[39m _extract_get_pydantic_json_schema(obj, schema)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadata_js_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:789\u001b[0m, in \u001b[0;36mGenerateSchema._generate_schema_inner\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, PydanticRecursiveRef):\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m core_schema\u001b[38;5;241m.\u001b[39mdefinition_reference_schema(schema_ref\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mtype_ref)\n\u001b[0;32m--> 789\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:875\u001b[0m, in \u001b[0;36mGenerateSchema.match_type\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arbitrary_types:\n\u001b[1;32m    874\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arbitrary_type_schema(obj)\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unknown_type_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:415\u001b[0m, in \u001b[0;36mGenerateSchema._unknown_type_schema\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_unknown_type_schema\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CoreSchema:\n\u001b[0;32m--> 415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticSchemaGenerationError(\n\u001b[1;32m    416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnable to generate pydantic-core schema for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    417\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSet `arbitrary_types_allowed=True` in the model_config to ignore this error\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or implement `__get_pydantic_core_schema__` on your type to fully support it.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf you got this error by calling handler(<some type>) within\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    420\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m `__get_pydantic_core_schema__` then you likely need to call\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    421\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m `handler.generate_schema(<some type>)` since we do not call\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    422\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m `__get_pydantic_core_schema__` on `<some type>` otherwise to avoid infinite recursion.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    423\u001b[0m     )\n",
      "\u001b[0;31mPydanticSchemaGenerationError\u001b[0m: Unable to generate pydantic-core schema for <class 'pandas.core.frame.DataFrame'>. Set `arbitrary_types_allowed=True` in the model_config to ignore this error or implement `__get_pydantic_core_schema__` on your type to fully support it.\n\nIf you got this error by calling handler(<some type>) within `__get_pydantic_core_schema__` then you likely need to call `handler.generate_schema(<some type>)` since we do not call `__get_pydantic_core_schema__` on `<some type>` otherwise to avoid infinite recursion.\n\nFor further information visit https://errors.pydantic.dev/2.8/u/schema-for-unknown-type"
     ]
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.document_stores.types import DuplicatePolicy\n",
    "from haystack.components.builders.prompt_builder import PromptBuilder\n",
    "from haystack_integrations.components.generators.ollama import OllamaGenerator\n",
    "from haystack_integrations.components.retrievers.qdrant import QdrantEmbeddingRetriever\n",
    "from haystack_integrations.document_stores.qdrant import QdrantDocumentStore\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder, SentenceTransformersDocumentEmbedder\n",
    "from haystack import Document\n",
    "\n",
    "# Function to read text file\n",
    "def read_text_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {file_path} was not found. Please make sure the file exists and the path is correct.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the file: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Read the text file\n",
    "file_path = \"1.PMAY-U 2.0 FAQ.txt\"  # Assuming you've converted the .docx to .txt\n",
    "document_content = read_text_file(file_path)\n",
    "\n",
    "if document_content is None:\n",
    "    print(\"Exiting due to file read error.\")\n",
    "    exit(1)\n",
    "\n",
    "# Initialize QdrantDocumentStore\n",
    "document_store = QdrantDocumentStore(\n",
    "    url='http://localhost:6333',\n",
    "    recreate_index=True,\n",
    "    return_embedding=True,\n",
    "    wait_result_from_api=True,\n",
    ")\n",
    "\n",
    "# Create a Document object\n",
    "document = Document(content=document_content)\n",
    "\n",
    "# Initialize and use SentenceTransformersDocumentEmbedder\n",
    "document_embedder = SentenceTransformersDocumentEmbedder()\n",
    "document_embedder.warm_up()\n",
    "documents_with_embeddings = document_embedder.run([document])\n",
    "\n",
    "# Write document to the document store\n",
    "document_store.write_documents(documents_with_embeddings.get(\"documents\"), policy=DuplicatePolicy.OVERWRITE)\n",
    "\n",
    "# Initialize QdrantEmbeddingRetriever\n",
    "retriever = QdrantEmbeddingRetriever(document_store=document_store)\n",
    "\n",
    "# Define the prompt template\n",
    "template = \"\"\"\n",
    "Given only the following information from the PMAY-U 2.0 FAQ document, answer the question.\n",
    "Ignore your own knowledge.\n",
    "Context:\n",
    "{% for document in documents %}\n",
    " {{ document.content }}\n",
    "{% endfor %}\n",
    "Question: {{ query }}\n",
    "\"\"\"\n",
    "\n",
    "# Set up the pipeline\n",
    "pipe = Pipeline()\n",
    "pipe.add_component(\"text_embedder\", SentenceTransformersTextEmbedder())\n",
    "pipe.add_component(\"retriever\", retriever)\n",
    "pipe.add_component(\"prompt_builder\", PromptBuilder(template=template))\n",
    "pipe.add_component(\"llm\", OllamaGenerator(model=\"llama3\", url=\"http://localhost:6333/api/generate\"))\n",
    "pipe.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
    "pipe.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "pipe.connect(\"prompt_builder\", \"llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 23.92it/s]\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "404 Client Error: Not Found for url: http://localhost:6333/api/generate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example query\u001b[39;00m\n\u001b[1;32m      2\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow Central Assistance will be released for Private Sector AHP Projects ?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_builder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext_embedder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplies\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env3.8/lib/python3.8/site-packages/haystack/core/pipeline/pipeline.py:233\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, data, debug, include_outputs_from)\u001b[0m\n\u001b[1;32m    230\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaximum loops count (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_loops_allowed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exceeded for component \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PipelineMaxLoops(msg)\n\u001b[0;32m--> 233\u001b[0m res: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_component\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponents_inputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m include_outputs_from:\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;66;03m# Deepcopy the outputs to prevent downstream nodes from modifying them\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;66;03m# We don't care about loops - Always store the last output.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     extra_outputs[name] \u001b[38;5;241m=\u001b[39m deepcopy(res)\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env3.8/lib/python3.8/site-packages/haystack/core/pipeline/pipeline.py:67\u001b[0m, in \u001b[0;36mPipeline._run_component\u001b[0;34m(self, name, inputs)\u001b[0m\n\u001b[1;32m     65\u001b[0m span\u001b[38;5;241m.\u001b[39mset_content_tag(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaystack.component.input\u001b[39m\u001b[38;5;124m\"\u001b[39m, inputs)\n\u001b[1;32m     66\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning component \u001b[39m\u001b[38;5;132;01m{component_name}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, component_name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m---> 67\u001b[0m res: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mnodes[name][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisits\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# After a Component that has variadic inputs is run, we need to reset the variadic inputs that were consumed\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env3.8/lib/python3.8/site-packages/haystack_integrations/components/generators/ollama/generator.py:198\u001b[0m, in \u001b[0;36mOllamaGenerator.run\u001b[0;34m(self, prompt, generation_kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl, json\u001b[38;5;241m=\u001b[39mjson_payload, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout, stream\u001b[38;5;241m=\u001b[39mstream)\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# throw error on unsuccessful response\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    201\u001b[0m     chunks: List[StreamingChunk] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_streaming_response(response)\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env3.8/lib/python3.8/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: http://localhost:6333/api/generate"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "query = \"How Central Assistance will be released for Private Sector AHP Projects ?\"\n",
    "response = pipe.run({\"prompt_builder\": {\"query\": query}, \"text_embedder\": {\"text\": query}})\n",
    "print(response[\"llm\"][\"replies\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
