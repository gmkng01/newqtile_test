{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting haystack\n",
      "  Using cached haystack-0.42-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting construct<2.8 (from haystack)\n",
      "  Using cached construct-2.5.3-py2.py3-none-any.whl\n",
      "Collecting pefile (from haystack)\n",
      "  Using cached pefile-2023.2.7-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-ptrace>=0.8.1 (from haystack)\n",
      "  Using cached python_ptrace-0.9.9-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: six in ./new_env/lib/python3.12/site-packages (from construct<2.8->haystack) (1.16.0)\n",
      "Using cached haystack-0.42-py2.py3-none-any.whl (179 kB)\n",
      "Using cached python_ptrace-0.9.9-py2.py3-none-any.whl (104 kB)\n",
      "Using cached pefile-2023.2.7-py3-none-any.whl (71 kB)\n",
      "Installing collected packages: python-ptrace, pefile, construct, haystack\n",
      "Successfully installed construct-2.5.3 haystack-0.42 pefile-2023.2.7 python-ptrace-0.9.9\n",
      "Requirement already satisfied: haystack-ai in ./new_env/lib/python3.12/site-packages (2.4.0)\n",
      "Requirement already satisfied: haystack-experimental in ./new_env/lib/python3.12/site-packages (from haystack-ai) (0.1.1)\n",
      "Requirement already satisfied: jinja2 in ./new_env/lib/python3.12/site-packages (from haystack-ai) (3.1.4)\n",
      "Requirement already satisfied: lazy-imports in ./new_env/lib/python3.12/site-packages (from haystack-ai) (0.3.1)\n",
      "Requirement already satisfied: more-itertools in ./new_env/lib/python3.12/site-packages (from haystack-ai) (10.4.0)\n",
      "Requirement already satisfied: networkx in ./new_env/lib/python3.12/site-packages (from haystack-ai) (3.3)\n",
      "Requirement already satisfied: numpy<2 in ./new_env/lib/python3.12/site-packages (from haystack-ai) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in ./new_env/lib/python3.12/site-packages (from haystack-ai) (1.42.0)\n",
      "Requirement already satisfied: pandas in ./new_env/lib/python3.12/site-packages (from haystack-ai) (2.2.2)\n",
      "Requirement already satisfied: posthog in ./new_env/lib/python3.12/site-packages (from haystack-ai) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil in ./new_env/lib/python3.12/site-packages (from haystack-ai) (2.9.0.post0)\n",
      "Requirement already satisfied: pyyaml in ./new_env/lib/python3.12/site-packages (from haystack-ai) (6.0.2)\n",
      "Requirement already satisfied: requests in ./new_env/lib/python3.12/site-packages (from haystack-ai) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0 in ./new_env/lib/python3.12/site-packages (from haystack-ai) (8.5.0)\n",
      "Requirement already satisfied: tqdm in ./new_env/lib/python3.12/site-packages (from haystack-ai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./new_env/lib/python3.12/site-packages (from haystack-ai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./new_env/lib/python3.12/site-packages (from openai>=1.1.0->haystack-ai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./new_env/lib/python3.12/site-packages (from openai>=1.1.0->haystack-ai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./new_env/lib/python3.12/site-packages (from openai>=1.1.0->haystack-ai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./new_env/lib/python3.12/site-packages (from openai>=1.1.0->haystack-ai) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./new_env/lib/python3.12/site-packages (from openai>=1.1.0->haystack-ai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in ./new_env/lib/python3.12/site-packages (from openai>=1.1.0->haystack-ai) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./new_env/lib/python3.12/site-packages (from jinja2->haystack-ai) (2.1.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./new_env/lib/python3.12/site-packages (from pandas->haystack-ai) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./new_env/lib/python3.12/site-packages (from pandas->haystack-ai) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in ./new_env/lib/python3.12/site-packages (from python-dateutil->haystack-ai) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in ./new_env/lib/python3.12/site-packages (from posthog->haystack-ai) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in ./new_env/lib/python3.12/site-packages (from posthog->haystack-ai) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./new_env/lib/python3.12/site-packages (from requests->haystack-ai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./new_env/lib/python3.12/site-packages (from requests->haystack-ai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./new_env/lib/python3.12/site-packages (from requests->haystack-ai) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./new_env/lib/python3.12/site-packages (from requests->haystack-ai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./new_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai>=1.1.0->haystack-ai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./new_env/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.1.0->haystack-ai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./new_env/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->haystack-ai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./new_env/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->haystack-ai) (2.20.1)\n",
      "Collecting farm-haystack[colab,elasticsearch,inference,preprocessing]\n",
      "  Using cached farm_haystack-1.26.2-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting boilerpy3 (from farm-haystack[colab,elasticsearch,inference,preprocessing])\n",
      "  Using cached boilerpy3-1.0.7-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting events (from farm-haystack[colab,elasticsearch,inference,preprocessing])\n",
      "  Using cached Events-0.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: httpx in ./new_env/lib/python3.12/site-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (0.27.0)\n",
      "Collecting jsonschema (from farm-haystack[colab,elasticsearch,inference,preprocessing])\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: lazy-imports==0.3.1 in ./new_env/lib/python3.12/site-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (0.3.1)\n",
      "Requirement already satisfied: more-itertools in ./new_env/lib/python3.12/site-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (10.4.0)\n",
      "Requirement already satisfied: networkx in ./new_env/lib/python3.12/site-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (3.3)\n",
      "Requirement already satisfied: pandas in ./new_env/lib/python3.12/site-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (2.2.2)\n",
      "Requirement already satisfied: pillow in ./new_env/lib/python3.12/site-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (10.4.0)\n",
      "Requirement already satisfied: platformdirs in ./new_env/lib/python3.12/site-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (4.2.2)\n",
      "Requirement already satisfied: posthog in ./new_env/lib/python3.12/site-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (3.5.0)\n",
      "Collecting prompthub-py==4.0.0 (from farm-haystack[colab,elasticsearch,inference,preprocessing])\n",
      "  Using cached prompthub_py-4.0.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pydantic<2 (from farm-haystack[colab,elasticsearch,inference,preprocessing])\n",
      "  Using cached pydantic-1.10.17-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (151 kB)\n",
      "Collecting quantulum3 (from farm-haystack[colab,elasticsearch,inference,preprocessing])\n",
      "  Using cached quantulum3-0.9.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting rank-bm25 (from farm-haystack[colab,elasticsearch,inference,preprocessing])\n",
      "  Using cached rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: requests in ./new_env/lib/python3.12/site-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (2.32.3)\n",
      "Collecting requests-cache<1.0.0 (from farm-haystack[colab,elasticsearch,inference,preprocessing])\n",
      "  Using cached requests_cache-0.9.8-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.3.0 in ./new_env/lib/python3.12/site-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (1.5.1)\n",
      "Collecting sseclient-py (from farm-haystack[colab,elasticsearch,inference,preprocessing])\n",
      "  Using cached sseclient_py-1.8.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: tenacity in ./new_env/lib/python3.12/site-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (8.5.0)\n",
      "Collecting tiktoken>=0.5.1 (from farm-haystack[colab,elasticsearch,inference,preprocessing])\n",
      "  Using cached tiktoken-0.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: tqdm in ./new_env/lib/python3.12/site-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (4.66.5)\n",
      "Collecting transformers==4.39.3 (from farm-haystack[colab,elasticsearch,inference,preprocessing])\n",
      "  Using cached transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\n",
      "Collecting pillow (from farm-haystack[colab,elasticsearch,inference,preprocessing])\n",
      "  Using cached Pillow-9.0.0-cp312-cp312-linux_x86_64.whl\n",
      "Collecting elastic-transport<8 (from farm-haystack[colab,elasticsearch,inference,preprocessing])\n",
      "  Using cached elastic_transport-7.16.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting elasticsearch<8,>=7.17 (from farm-haystack[colab,elasticsearch,inference,preprocessing])\n",
      "  Using cached elasticsearch-7.17.9-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.5.0 in ./new_env/lib/python3.12/site-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (0.24.6)\n",
      "Requirement already satisfied: sentence-transformers>=2.2.0 in ./new_env/lib/python3.12/site-packages (from farm-haystack[colab,elasticsearch,inference,preprocessing]) (3.0.1)\n",
      "Collecting langdetect (from farm-haystack[colab,elasticsearch,inference,preprocessing])\n",
      "  Using cached langdetect-1.0.9.tar.gz (981 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting nltk (from farm-haystack[colab,elasticsearch,inference,preprocessing])\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=6.0 in ./new_env/lib/python3.12/site-packages (from prompthub-py==4.0.0->farm-haystack[colab,elasticsearch,inference,preprocessing]) (6.0.2)\n",
      "Requirement already satisfied: filelock in ./new_env/lib/python3.12/site-packages (from transformers==4.39.3->farm-haystack[colab,elasticsearch,inference,preprocessing]) (3.15.4)\n",
      "Requirement already satisfied: numpy>=1.17 in ./new_env/lib/python3.12/site-packages (from transformers==4.39.3->farm-haystack[colab,elasticsearch,inference,preprocessing]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./new_env/lib/python3.12/site-packages (from transformers==4.39.3->farm-haystack[colab,elasticsearch,inference,preprocessing]) (24.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./new_env/lib/python3.12/site-packages (from transformers==4.39.3->farm-haystack[colab,elasticsearch,inference,preprocessing]) (2024.7.24)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.39.3->farm-haystack[colab,elasticsearch,inference,preprocessing])\n",
      "  Using cached tokenizers-0.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./new_env/lib/python3.12/site-packages (from transformers==4.39.3->farm-haystack[colab,elasticsearch,inference,preprocessing]) (0.4.4)\n",
      "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece,torch]==4.39.3; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing])\n",
      "  Using cached sentencepiece-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: protobuf in ./new_env/lib/python3.12/site-packages (from transformers[sentencepiece,torch]==4.39.3; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (4.25.4)\n",
      "Requirement already satisfied: torch in ./new_env/lib/python3.12/site-packages (from transformers[sentencepiece,torch]==4.39.3; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (2.4.0)\n",
      "Collecting accelerate>=0.21.0 (from transformers[sentencepiece,torch]==4.39.3; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing])\n",
      "  Using cached accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting urllib3<2,>=1.21.1 (from elastic-transport<8->farm-haystack[colab,elasticsearch,inference,preprocessing])\n",
      "  Using cached urllib3-1.26.19-py2.py3-none-any.whl.metadata (49 kB)\n",
      "Requirement already satisfied: six>=1.12 in ./new_env/lib/python3.12/site-packages (from elastic-transport<8->farm-haystack[colab,elasticsearch,inference,preprocessing]) (1.16.0)\n",
      "Requirement already satisfied: certifi in ./new_env/lib/python3.12/site-packages (from elastic-transport<8->farm-haystack[colab,elasticsearch,inference,preprocessing]) (2024.7.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./new_env/lib/python3.12/site-packages (from huggingface-hub>=0.5.0->farm-haystack[colab,elasticsearch,inference,preprocessing]) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./new_env/lib/python3.12/site-packages (from huggingface-hub>=0.5.0->farm-haystack[colab,elasticsearch,inference,preprocessing]) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./new_env/lib/python3.12/site-packages (from requests->farm-haystack[colab,elasticsearch,inference,preprocessing]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./new_env/lib/python3.12/site-packages (from requests->farm-haystack[colab,elasticsearch,inference,preprocessing]) (3.7)\n",
      "Collecting appdirs>=1.4.4 (from requests-cache<1.0.0->farm-haystack[colab,elasticsearch,inference,preprocessing])\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: attrs>=21.2 in ./new_env/lib/python3.12/site-packages (from requests-cache<1.0.0->farm-haystack[colab,elasticsearch,inference,preprocessing]) (24.2.0)\n",
      "Collecting cattrs>=22.2 (from requests-cache<1.0.0->farm-haystack[colab,elasticsearch,inference,preprocessing])\n",
      "  Using cached cattrs-23.2.3-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting url-normalize>=1.4 (from requests-cache<1.0.0->farm-haystack[colab,elasticsearch,inference,preprocessing])\n",
      "  Using cached url_normalize-1.4.3-py2.py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./new_env/lib/python3.12/site-packages (from scikit-learn>=1.3.0->farm-haystack[colab,elasticsearch,inference,preprocessing]) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./new_env/lib/python3.12/site-packages (from scikit-learn>=1.3.0->farm-haystack[colab,elasticsearch,inference,preprocessing]) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./new_env/lib/python3.12/site-packages (from scikit-learn>=1.3.0->farm-haystack[colab,elasticsearch,inference,preprocessing]) (3.5.0)\n",
      "Requirement already satisfied: anyio in ./new_env/lib/python3.12/site-packages (from httpx->farm-haystack[colab,elasticsearch,inference,preprocessing]) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./new_env/lib/python3.12/site-packages (from httpx->farm-haystack[colab,elasticsearch,inference,preprocessing]) (1.0.5)\n",
      "Requirement already satisfied: sniffio in ./new_env/lib/python3.12/site-packages (from httpx->farm-haystack[colab,elasticsearch,inference,preprocessing]) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./new_env/lib/python3.12/site-packages (from httpcore==1.*->httpx->farm-haystack[colab,elasticsearch,inference,preprocessing]) (0.14.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->farm-haystack[colab,elasticsearch,inference,preprocessing])\n",
      "  Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema->farm-haystack[colab,elasticsearch,inference,preprocessing])\n",
      "  Using cached referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema->farm-haystack[colab,elasticsearch,inference,preprocessing])\n",
      "  Using cached rpds_py-0.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: click in ./new_env/lib/python3.12/site-packages (from nltk->farm-haystack[colab,elasticsearch,inference,preprocessing]) (8.1.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./new_env/lib/python3.12/site-packages (from pandas->farm-haystack[colab,elasticsearch,inference,preprocessing]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./new_env/lib/python3.12/site-packages (from pandas->farm-haystack[colab,elasticsearch,inference,preprocessing]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./new_env/lib/python3.12/site-packages (from pandas->farm-haystack[colab,elasticsearch,inference,preprocessing]) (2024.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in ./new_env/lib/python3.12/site-packages (from posthog->farm-haystack[colab,elasticsearch,inference,preprocessing]) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in ./new_env/lib/python3.12/site-packages (from posthog->farm-haystack[colab,elasticsearch,inference,preprocessing]) (2.2.1)\n",
      "Requirement already satisfied: inflect in ./new_env/lib/python3.12/site-packages (from quantulum3->farm-haystack[colab,elasticsearch,inference,preprocessing]) (7.3.1)\n",
      "Collecting num2words (from quantulum3->farm-haystack[colab,elasticsearch,inference,preprocessing])\n",
      "  Using cached num2words-0.5.13-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: psutil in ./new_env/lib/python3.12/site-packages (from accelerate>=0.21.0->transformers[sentencepiece,torch]==4.39.3; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (6.0.0)\n",
      "Requirement already satisfied: sympy in ./new_env/lib/python3.12/site-packages (from torch->transformers[sentencepiece,torch]==4.39.3; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (1.13.2)\n",
      "Requirement already satisfied: jinja2 in ./new_env/lib/python3.12/site-packages (from torch->transformers[sentencepiece,torch]==4.39.3; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (3.1.4)\n",
      "Requirement already satisfied: setuptools in ./new_env/lib/python3.12/site-packages (from torch->transformers[sentencepiece,torch]==4.39.3; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (73.0.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./new_env/lib/python3.12/site-packages (from torch->transformers[sentencepiece,torch]==4.39.3; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./new_env/lib/python3.12/site-packages (from torch->transformers[sentencepiece,torch]==4.39.3; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./new_env/lib/python3.12/site-packages (from torch->transformers[sentencepiece,torch]==4.39.3; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./new_env/lib/python3.12/site-packages (from torch->transformers[sentencepiece,torch]==4.39.3; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./new_env/lib/python3.12/site-packages (from torch->transformers[sentencepiece,torch]==4.39.3; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./new_env/lib/python3.12/site-packages (from torch->transformers[sentencepiece,torch]==4.39.3; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./new_env/lib/python3.12/site-packages (from torch->transformers[sentencepiece,torch]==4.39.3; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./new_env/lib/python3.12/site-packages (from torch->transformers[sentencepiece,torch]==4.39.3; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./new_env/lib/python3.12/site-packages (from torch->transformers[sentencepiece,torch]==4.39.3; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./new_env/lib/python3.12/site-packages (from torch->transformers[sentencepiece,torch]==4.39.3; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./new_env/lib/python3.12/site-packages (from torch->transformers[sentencepiece,torch]==4.39.3; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in ./new_env/lib/python3.12/site-packages (from torch->transformers[sentencepiece,torch]==4.39.3; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./new_env/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[sentencepiece,torch]==4.39.3; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (12.6.20)\n",
      "Requirement already satisfied: typeguard>=4.0.1 in ./new_env/lib/python3.12/site-packages (from inflect->quantulum3->farm-haystack[colab,elasticsearch,inference,preprocessing]) (4.3.0)\n",
      "Collecting docopt>=0.6.2 (from num2words->quantulum3->farm-haystack[colab,elasticsearch,inference,preprocessing])\n",
      "  Using cached docopt-0.6.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./new_env/lib/python3.12/site-packages (from jinja2->torch->transformers[sentencepiece,torch]==4.39.3; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./new_env/lib/python3.12/site-packages (from sympy->torch->transformers[sentencepiece,torch]==4.39.3; extra == \"inference\"->farm-haystack[colab,elasticsearch,inference,preprocessing]) (1.3.0)\n",
      "Using cached prompthub_py-4.0.0-py3-none-any.whl (6.9 kB)\n",
      "Using cached transformers-4.39.3-py3-none-any.whl (8.8 MB)\n",
      "Using cached elastic_transport-7.16.0-py2.py3-none-any.whl (35 kB)\n",
      "Using cached elasticsearch-7.17.9-py2.py3-none-any.whl (385 kB)\n",
      "Using cached pydantic-1.10.17-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
      "Using cached requests_cache-0.9.8-py3-none-any.whl (48 kB)\n",
      "Using cached tiktoken-0.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Using cached boilerpy3-1.0.7-py3-none-any.whl (22 kB)\n",
      "Using cached Events-0.5-py3-none-any.whl (6.8 kB)\n",
      "Using cached farm_haystack-1.26.2-py3-none-any.whl (763 kB)\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached quantulum3-0.9.2-py3-none-any.whl (10.6 MB)\n",
      "Using cached rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Using cached sseclient_py-1.8.0-py2.py3-none-any.whl (8.8 kB)\n",
      "Using cached accelerate-0.33.0-py3-none-any.whl (315 kB)\n",
      "Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached cattrs-23.2.3-py3-none-any.whl (57 kB)\n",
      "Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Using cached referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Using cached rpds_py-0.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (357 kB)\n",
      "Using cached sentencepiece-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Using cached tokenizers-0.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Using cached url_normalize-1.4.3-py2.py3-none-any.whl (6.8 kB)\n",
      "Using cached urllib3-1.26.19-py2.py3-none-any.whl (143 kB)\n",
      "Using cached num2words-0.5.13-py3-none-any.whl (143 kB)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993221 sha256=0bbd913075b07706fdf44d121fc2dceec569ef570dd3d2caacbb6e678b7737b0\n",
      "  Stored in directory: /home/abhi/.cache/pip/wheels/c1/67/88/e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
      "Successfully built langdetect\n",
      "Installing collected packages: sseclient-py, sentencepiece, events, docopt, appdirs, urllib3, url-normalize, rpds-py, rank-bm25, pydantic, pillow, num2words, nltk, langdetect, cattrs, boilerpy3, referencing, elasticsearch, elastic-transport, tiktoken, requests-cache, quantulum3, prompthub-py, jsonschema-specifications, tokenizers, jsonschema, accelerate, transformers, farm-haystack\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.2\n",
      "    Uninstalling urllib3-2.2.2:\n",
      "      Successfully uninstalled urllib3-2.2.2\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.8.2\n",
      "    Uninstalling pydantic-2.8.2:\n",
      "      Successfully uninstalled pydantic-2.8.2\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 10.4.0\n",
      "    Uninstalling pillow-10.4.0:\n",
      "      Successfully uninstalled pillow-10.4.0\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.19.1\n",
      "    Uninstalling tokenizers-0.19.1:\n",
      "      Successfully uninstalled tokenizers-0.19.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.44.1\n",
      "    Uninstalling transformers-4.44.1:\n",
      "      Successfully uninstalled transformers-4.44.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradio 4.41.0 requires pydantic>=2.0, but you have pydantic 1.10.17 which is incompatible.\n",
      "gradio 4.41.0 requires urllib3~=2.0, but you have urllib3 1.26.19 which is incompatible.\n",
      "langchain-core 0.2.33 requires pydantic<3.0.0,>=2.7.4; python_full_version >= \"3.12.4\", but you have pydantic 1.10.17 which is incompatible.\n",
      "langsmith 0.1.100 requires pydantic<3.0.0,>=2.7.4; python_full_version >= \"3.12.4\", but you have pydantic 1.10.17 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-0.33.0 appdirs-1.4.4 boilerpy3-1.0.7 cattrs-23.2.3 docopt-0.6.2 elastic-transport-7.16.0 elasticsearch-7.17.9 events-0.5 farm-haystack-1.26.2 jsonschema-4.23.0 jsonschema-specifications-2023.12.1 langdetect-1.0.9 nltk-3.9.1 num2words-0.5.13 pillow-9.0.0 prompthub-py-4.0.0 pydantic-1.10.17 quantulum3-0.9.2 rank-bm25-0.2.2 referencing-0.35.1 requests-cache-0.9.8 rpds-py-0.20.0 sentencepiece-0.2.0 sseclient-py-1.8.0 tiktoken-0.7.0 tokenizers-0.15.2 transformers-4.39.3 url-normalize-1.4.3 urllib3-1.26.19\n",
      "Requirement already satisfied: backports.tarfile in ./new_env/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: chromadb in ./new_env/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (0.5.5)\n",
      "Requirement already satisfied: datasets in ./new_env/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (2.20.0)\n",
      "Requirement already satisfied: gradio in ./new_env/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (4.41.0)\n",
      "Requirement already satisfied: h2 in ./new_env/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (4.1.0)\n",
      "Requirement already satisfied: httptools in ./new_env/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (0.6.1)\n",
      "Requirement already satisfied: ipykernel in ./new_env/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (6.29.5)\n",
      "Requirement already satisfied: jaraco.text in ./new_env/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (3.12.1)\n",
      "Requirement already satisfied: langchain-community in ./new_env/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (0.2.12)\n",
      "Requirement already satisfied: ollama-haystack in ./new_env/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (0.0.7)\n",
      "Requirement already satisfied: ordered-set in ./new_env/lib/python3.12/site-packages (from -r requirements.txt (line 11)) (4.1.0)\n",
      "Requirement already satisfied: pip-chill in ./new_env/lib/python3.12/site-packages (from -r requirements.txt (line 12)) (1.0.3)\n",
      "Requirement already satisfied: pypdf in ./new_env/lib/python3.12/site-packages (from -r requirements.txt (line 13)) (4.3.1)\n",
      "Requirement already satisfied: python-dotenv in ./new_env/lib/python3.12/site-packages (from -r requirements.txt (line 14)) (1.0.1)\n",
      "Requirement already satisfied: pydantic in ./new_env/lib/python3.12/site-packages (from -r requirements.txt (line 15)) (1.10.17)\n",
      "Requirement already satisfied: urllib3 in ./new_env/lib/python3.12/site-packages (from -r requirements.txt (line 16)) (1.26.19)\n",
      "Requirement already satisfied: qdrant-haystack in ./new_env/lib/python3.12/site-packages (from -r requirements.txt (line 17)) (4.1.2)\n",
      "Requirement already satisfied: sentence-transformers in ./new_env/lib/python3.12/site-packages (from -r requirements.txt (line 18)) (3.0.1)\n",
      "Requirement already satisfied: tomli in ./new_env/lib/python3.12/site-packages (from -r requirements.txt (line 19)) (2.0.1)\n",
      "Requirement already satisfied: uvloop in ./new_env/lib/python3.12/site-packages (from -r requirements.txt (line 20)) (0.19.0)\n",
      "Requirement already satisfied: watchfiles in ./new_env/lib/python3.12/site-packages (from -r requirements.txt (line 21)) (0.23.0)\n",
      "Requirement already satisfied: build>=1.0.3 in ./new_env/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 2)) (1.2.1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in ./new_env/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 2)) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in ./new_env/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 2)) (0.112.1)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in ./new_env/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 2)) (0.30.6)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.22.5 in ./new_env/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: posthog>=2.4.0 in ./new_env/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 2)) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./new_env/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 2)) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in ./new_env/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 2)) (1.19.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in ./new_env/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 2)) (1.26.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in ./new_env/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 2)) (1.26.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in ./new_env/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 2)) (0.47b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in ./new_env/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 2)) (1.26.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in ./new_env/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 2)) (0.15.2)\n",
      "Requirement already satisfied: pypika>=0.48.9 in ./new_env/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 2)) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in ./new_env/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 2)) (4.66.5)\n",
      "Requirement already satisfied: overrides>=7.3.1 in ./new_env/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 2)) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in ./new_env/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 2)) (6.4.3)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in ./new_env/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 2)) (1.65.5)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in ./new_env/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 2)) (4.2.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in ./new_env/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 2)) (0.12.4)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in ./new_env/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 2)) (30.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in ./new_env/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 2)) (8.5.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in ./new_env/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 2)) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in ./new_env/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 2)) (4.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in ./new_env/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 2)) (3.10.7)\n",
      "Requirement already satisfied: httpx>=0.27.0 in ./new_env/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 2)) (0.27.0)\n",
      "Requirement already satisfied: filelock in ./new_env/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 3)) (3.15.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./new_env/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 3)) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in ./new_env/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 3)) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./new_env/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 3)) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./new_env/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 3)) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./new_env/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 3)) (2.32.3)\n",
      "Requirement already satisfied: xxhash in ./new_env/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 3)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in ./new_env/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 3)) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in ./new_env/lib/python3.12/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets->-r requirements.txt (line 3)) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in ./new_env/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 3)) (3.10.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in ./new_env/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 3)) (0.24.6)\n",
      "Requirement already satisfied: packaging in ./new_env/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 3)) (24.1)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in ./new_env/lib/python3.12/site-packages (from gradio->-r requirements.txt (line 4)) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in ./new_env/lib/python3.12/site-packages (from gradio->-r requirements.txt (line 4)) (4.4.0)\n",
      "Requirement already satisfied: ffmpy in ./new_env/lib/python3.12/site-packages (from gradio->-r requirements.txt (line 4)) (0.4.0)\n",
      "Requirement already satisfied: gradio-client==1.3.0 in ./new_env/lib/python3.12/site-packages (from gradio->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: jinja2<4.0 in ./new_env/lib/python3.12/site-packages (from gradio->-r requirements.txt (line 4)) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in ./new_env/lib/python3.12/site-packages (from gradio->-r requirements.txt (line 4)) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in ./new_env/lib/python3.12/site-packages (from gradio->-r requirements.txt (line 4)) (3.9.2)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in ./new_env/lib/python3.12/site-packages (from gradio->-r requirements.txt (line 4)) (9.0.0)\n",
      "Collecting pydantic (from -r requirements.txt (line 15))\n",
      "  Using cached pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
      "Requirement already satisfied: pydub in ./new_env/lib/python3.12/site-packages (from gradio->-r requirements.txt (line 4)) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in ./new_env/lib/python3.12/site-packages (from gradio->-r requirements.txt (line 4)) (0.0.9)\n",
      "Requirement already satisfied: ruff>=0.2.2 in ./new_env/lib/python3.12/site-packages (from gradio->-r requirements.txt (line 4)) (0.6.1)\n",
      "Requirement already satisfied: semantic-version~=2.0 in ./new_env/lib/python3.12/site-packages (from gradio->-r requirements.txt (line 4)) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in ./new_env/lib/python3.12/site-packages (from gradio->-r requirements.txt (line 4)) (0.12.0)\n",
      "Collecting urllib3 (from -r requirements.txt (line 16))\n",
      "  Using cached urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in ./new_env/lib/python3.12/site-packages (from gradio-client==1.3.0->gradio->-r requirements.txt (line 4)) (12.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in ./new_env/lib/python3.12/site-packages (from h2->-r requirements.txt (line 5)) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in ./new_env/lib/python3.12/site-packages (from h2->-r requirements.txt (line 5)) (4.0.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in ./new_env/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 7)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./new_env/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 7)) (1.8.5)\n",
      "Requirement already satisfied: ipython>=7.23.1 in ./new_env/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 7)) (8.26.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in ./new_env/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 7)) (8.6.2)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./new_env/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 7)) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./new_env/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 7)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in ./new_env/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 7)) (1.6.0)\n",
      "Requirement already satisfied: psutil in ./new_env/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 7)) (6.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in ./new_env/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 7)) (26.1.1)\n",
      "Requirement already satisfied: tornado>=6.1 in ./new_env/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 7)) (6.4.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in ./new_env/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 7)) (5.14.3)\n",
      "Requirement already satisfied: jaraco.functools in ./new_env/lib/python3.12/site-packages (from jaraco.text->-r requirements.txt (line 8)) (4.0.2)\n",
      "Requirement already satisfied: jaraco.context>=4.1 in ./new_env/lib/python3.12/site-packages (from jaraco.text->-r requirements.txt (line 8)) (6.0.1)\n",
      "Requirement already satisfied: autocommand in ./new_env/lib/python3.12/site-packages (from jaraco.text->-r requirements.txt (line 8)) (2.2.2)\n",
      "Requirement already satisfied: inflect in ./new_env/lib/python3.12/site-packages (from jaraco.text->-r requirements.txt (line 8)) (7.3.1)\n",
      "Requirement already satisfied: more-itertools in ./new_env/lib/python3.12/site-packages (from jaraco.text->-r requirements.txt (line 8)) (10.4.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./new_env/lib/python3.12/site-packages (from langchain-community->-r requirements.txt (line 9)) (2.0.32)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./new_env/lib/python3.12/site-packages (from langchain-community->-r requirements.txt (line 9)) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.13 in ./new_env/lib/python3.12/site-packages (from langchain-community->-r requirements.txt (line 9)) (0.2.14)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.30 in ./new_env/lib/python3.12/site-packages (from langchain-community->-r requirements.txt (line 9)) (0.2.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in ./new_env/lib/python3.12/site-packages (from langchain-community->-r requirements.txt (line 9)) (0.1.100)\n",
      "Requirement already satisfied: haystack-ai in ./new_env/lib/python3.12/site-packages (from ollama-haystack->-r requirements.txt (line 10)) (2.4.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./new_env/lib/python3.12/site-packages (from pydantic->-r requirements.txt (line 15)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./new_env/lib/python3.12/site-packages (from pydantic->-r requirements.txt (line 15)) (2.20.1)\n",
      "Requirement already satisfied: qdrant-client>=1.10.0 in ./new_env/lib/python3.12/site-packages (from qdrant-haystack->-r requirements.txt (line 17)) (1.11.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in ./new_env/lib/python3.12/site-packages (from sentence-transformers->-r requirements.txt (line 18)) (4.39.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./new_env/lib/python3.12/site-packages (from sentence-transformers->-r requirements.txt (line 18)) (2.4.0)\n",
      "Requirement already satisfied: scikit-learn in ./new_env/lib/python3.12/site-packages (from sentence-transformers->-r requirements.txt (line 18)) (1.5.1)\n",
      "Requirement already satisfied: scipy in ./new_env/lib/python3.12/site-packages (from sentence-transformers->-r requirements.txt (line 18)) (1.14.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./new_env/lib/python3.12/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./new_env/lib/python3.12/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./new_env/lib/python3.12/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./new_env/lib/python3.12/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./new_env/lib/python3.12/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./new_env/lib/python3.12/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.9.4)\n",
      "Requirement already satisfied: idna>=2.8 in ./new_env/lib/python3.12/site-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 4)) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./new_env/lib/python3.12/site-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: pyproject_hooks in ./new_env/lib/python3.12/site-packages (from build>=1.0.3->chromadb->-r requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./new_env/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 9)) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./new_env/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 9)) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in ./new_env/lib/python3.12/site-packages (from fastapi>=0.95.2->chromadb->-r requirements.txt (line 2)) (0.38.2)\n",
      "Requirement already satisfied: certifi in ./new_env/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb->-r requirements.txt (line 2)) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./new_env/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb->-r requirements.txt (line 2)) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./new_env/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb->-r requirements.txt (line 2)) (0.14.0)\n",
      "Requirement already satisfied: decorator in ./new_env/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./new_env/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in ./new_env/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./new_env/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (2.18.0)\n",
      "Requirement already satisfied: stack-data in ./new_env/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in ./new_env/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (4.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./new_env/lib/python3.12/site-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 7)) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./new_env/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 7)) (4.2.2)\n",
      "Requirement already satisfied: six>=1.9.0 in ./new_env/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in ./new_env/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (2.34.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in ./new_env/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in ./new_env/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in ./new_env/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (3.2.2)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in ./new_env/lib/python3.12/site-packages (from langchain<0.3.0,>=0.2.13->langchain-community->-r requirements.txt (line 9)) (0.2.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./new_env/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.30->langchain-community->-r requirements.txt (line 9)) (1.33)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./new_env/lib/python3.12/site-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 4)) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./new_env/lib/python3.12/site-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./new_env/lib/python3.12/site-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 4)) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./new_env/lib/python3.12/site-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 4)) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./new_env/lib/python3.12/site-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 4)) (3.1.2)\n",
      "Requirement already satisfied: coloredlogs in ./new_env/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 2)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in ./new_env/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 2)) (24.3.25)\n",
      "Requirement already satisfied: protobuf in ./new_env/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 2)) (4.25.4)\n",
      "Requirement already satisfied: sympy in ./new_env/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 2)) (1.13.2)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in ./new_env/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 2)) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<=8.0.0,>=6.0 in ./new_env/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 2)) (8.0.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in ./new_env/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 2)) (1.63.2)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.26.0 in ./new_env/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 2)) (1.26.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.26.0 in ./new_env/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 2)) (1.26.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.47b0 in ./new_env/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 2)) (0.47b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.47b0 in ./new_env/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 2)) (0.47b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.47b0 in ./new_env/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 2)) (0.47b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.47b0 in ./new_env/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 2)) (0.47b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in ./new_env/lib/python3.12/site-packages (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 2)) (73.0.1)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in ./new_env/lib/python3.12/site-packages (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in ./new_env/lib/python3.12/site-packages (from opentelemetry-instrumentation-asgi==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 2)) (3.8.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./new_env/lib/python3.12/site-packages (from pandas->datasets->-r requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./new_env/lib/python3.12/site-packages (from pandas->datasets->-r requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in ./new_env/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb->-r requirements.txt (line 2)) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in ./new_env/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb->-r requirements.txt (line 2)) (2.2.1)\n",
      "Requirement already satisfied: grpcio-tools>=1.41.0 in ./new_env/lib/python3.12/site-packages (from qdrant-client>=1.10.0->qdrant-haystack->-r requirements.txt (line 17)) (1.62.3)\n",
      "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in ./new_env/lib/python3.12/site-packages (from qdrant-client>=1.10.0->qdrant-haystack->-r requirements.txt (line 17)) (2.10.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./new_env/lib/python3.12/site-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./new_env/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain-community->-r requirements.txt (line 9)) (3.0.3)\n",
      "Requirement already satisfied: networkx in ./new_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 18)) (3.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./new_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 18)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./new_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 18)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./new_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 18)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./new_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 18)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./new_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 18)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./new_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 18)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./new_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 18)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./new_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 18)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./new_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 18)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./new_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 18)) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./new_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 18)) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in ./new_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 18)) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./new_env/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers->-r requirements.txt (line 18)) (12.6.20)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./new_env/lib/python3.12/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers->-r requirements.txt (line 18)) (2024.7.24)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./new_env/lib/python3.12/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers->-r requirements.txt (line 18)) (0.4.4)\n",
      "Requirement already satisfied: click>=8.0.0 in ./new_env/lib/python3.12/site-packages (from typer>=0.9.0->chromadb->-r requirements.txt (line 2)) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./new_env/lib/python3.12/site-packages (from typer>=0.9.0->chromadb->-r requirements.txt (line 2)) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./new_env/lib/python3.12/site-packages (from typer>=0.9.0->chromadb->-r requirements.txt (line 2)) (13.7.1)\n",
      "Requirement already satisfied: haystack-experimental in ./new_env/lib/python3.12/site-packages (from haystack-ai->ollama-haystack->-r requirements.txt (line 10)) (0.1.1)\n",
      "Requirement already satisfied: lazy-imports in ./new_env/lib/python3.12/site-packages (from haystack-ai->ollama-haystack->-r requirements.txt (line 10)) (0.3.1)\n",
      "Requirement already satisfied: openai>=1.1.0 in ./new_env/lib/python3.12/site-packages (from haystack-ai->ollama-haystack->-r requirements.txt (line 10)) (1.42.0)\n",
      "Requirement already satisfied: typeguard>=4.0.1 in ./new_env/lib/python3.12/site-packages (from inflect->jaraco.text->-r requirements.txt (line 8)) (4.3.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./new_env/lib/python3.12/site-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 18)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./new_env/lib/python3.12/site-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 18)) (3.5.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./new_env/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./new_env/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./new_env/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (4.9)\n",
      "Requirement already satisfied: zipp>=0.5 in ./new_env/lib/python3.12/site-packages (from importlib-metadata<=8.0.0,>=6.0->opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 2)) (3.20.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./new_env/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (0.8.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./new_env/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.30->langchain-community->-r requirements.txt (line 9)) (3.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./new_env/lib/python3.12/site-packages (from openai>=1.1.0->haystack-ai->ollama-haystack->-r requirements.txt (line 10)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./new_env/lib/python3.12/site-packages (from openai>=1.1.0->haystack-ai->ollama-haystack->-r requirements.txt (line 10)) (0.5.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./new_env/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./new_env/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (0.2.13)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./new_env/lib/python3.12/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb->-r requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./new_env/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 9)) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./new_env/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 2)) (10.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./new_env/lib/python3.12/site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./new_env/lib/python3.12/site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in ./new_env/lib/python3.12/site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (0.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./new_env/lib/python3.12/site-packages (from sympy->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./new_env/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb->-r requirements.txt (line 2)) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in ./new_env/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (0.6.0)\n",
      "Using cached pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "Using cached urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
      "Installing collected packages: urllib3, pydantic\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.19\n",
      "    Uninstalling urllib3-1.26.19:\n",
      "      Successfully uninstalled urllib3-1.26.19\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.17\n",
      "    Uninstalling pydantic-1.10.17:\n",
      "      Successfully uninstalled pydantic-1.10.17\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "elasticsearch 7.17.9 requires urllib3<2,>=1.21.1, but you have urllib3 2.2.2 which is incompatible.\n",
      "farm-haystack 1.26.2 requires pydantic<2, but you have pydantic 2.8.2 which is incompatible.\n",
      "elastic-transport 7.16.0 requires urllib3<2,>=1.21.1, but you have urllib3 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pydantic-2.8.2 urllib3-2.2.2\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade pip\n",
    "! pip install haystack \n",
    "!pip install haystack-ai\n",
    "# !pip install farm-haystack[colab,inference]\n",
    "# !pip3.10 uninstall pydantic urllib3\n",
    "!pip install farm-haystack[colab,preprocessing,elasticsearch,inference]\n",
    "!pip install -r requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "PydanticSchemaGenerationError",
     "evalue": "Unable to generate pydantic-core schema for <class 'pandas.core.frame.DataFrame'>. Set `arbitrary_types_allowed=True` in the model_config to ignore this error or implement `__get_pydantic_core_schema__` on your type to fully support it.\n\nIf you got this error by calling handler(<some type>) within `__get_pydantic_core_schema__` then you likely need to call `handler.generate_schema(<some type>)` since we do not call `__get_pydantic_core_schema__` on `<some type>` otherwise to avoid infinite recursion.\n\nFor further information visit https://errors.pydantic.dev/2.8/u/schema-for-unknown-type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPydanticSchemaGenerationError\u001b[0m             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhaystack\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhaystack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_stores\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DuplicatePolicy\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhaystack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompt_builder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptBuilder\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/haystack/__init__.py:10\u001b[0m\n\u001b[1;32m      6\u001b[0m __version__: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(metadata\u001b[38;5;241m.\u001b[39mversion(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfarm-haystack\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhaystack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msilenceable_tqdm\u001b[39;00m  \u001b[38;5;66;03m# Needs to be imported first to wrap TQDM for all following modules\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhaystack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Document, Answer, Label, MultiLabel, Span, EvaluationResult, TableCell\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhaystack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnodes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseComponent\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhaystack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipelines\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/haystack/schema.py:41\u001b[0m\n\u001b[1;32m     36\u001b[0m FilterType \u001b[38;5;241m=\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], List[Any], \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mbool\u001b[39m]]\n\u001b[1;32m     38\u001b[0m LABEL_DATETIME_FORMAT: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;129;43m@dataclass\u001b[39;49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mDocument\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mUnion\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/dataclasses.py:258\u001b[0m, in \u001b[0;36mdataclass\u001b[0;34m(_cls, init, repr, eq, order, unsafe_hash, frozen, config, validate_on_init, kw_only, slots)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cls \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m create_dataclass\n\u001b[0;32m--> 258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_dataclass\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_cls\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/dataclasses.py:249\u001b[0m, in \u001b[0;36mdataclass.<locals>.create_dataclass\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m \u001b[38;5;241m=\u001b[39m original_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;241m=\u001b[39m original_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\n\u001b[0;32m--> 249\u001b[0m pydantic_complete \u001b[38;5;241m=\u001b[39m \u001b[43m_pydantic_dataclasses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete_dataclass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_wrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes_namespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    251\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_complete__ \u001b[38;5;241m=\u001b[39m pydantic_complete  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_dataclasses.py:160\u001b[0m, in \u001b[0;36mcomplete_dataclass\u001b[0;34m(cls, config_wrapper, raise_errors, types_namespace)\u001b[0m\n\u001b[1;32m    151\u001b[0m         schema \u001b[38;5;241m=\u001b[39m get_core_schema(\n\u001b[1;32m    152\u001b[0m             \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m    153\u001b[0m             CallbackGetCoreSchemaHandler(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    157\u001b[0m             ),\n\u001b[1;32m    158\u001b[0m         )\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m         schema \u001b[38;5;241m=\u001b[39m \u001b[43mgen_schema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_dunder_get_core_schema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PydanticUndefinedAnnotation \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raise_errors:\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:512\u001b[0m, in \u001b[0;36mGenerateSchema.generate_schema\u001b[0;34m(self, obj, from_dunder_get_core_schema)\u001b[0m\n\u001b[1;32m    509\u001b[0m         schema \u001b[38;5;241m=\u001b[39m from_property\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 512\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_schema_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    514\u001b[0m metadata_js_function \u001b[38;5;241m=\u001b[39m _extract_get_pydantic_json_schema(obj, schema)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadata_js_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:789\u001b[0m, in \u001b[0;36mGenerateSchema._generate_schema_inner\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, PydanticRecursiveRef):\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m core_schema\u001b[38;5;241m.\u001b[39mdefinition_reference_schema(schema_ref\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mtype_ref)\n\u001b[0;32m--> 789\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:863\u001b[0m, in \u001b[0;36mGenerateSchema.match_type\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_enum_core_schema(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config_wrapper\u001b[38;5;241m.\u001b[39mconfig_dict)\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _typing_extra\u001b[38;5;241m.\u001b[39mis_dataclass(obj):\n\u001b[0;32m--> 863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataclass_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    864\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_prepare_pydantic_annotations_for_known_type(obj, ())\n\u001b[1;32m    865\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:1619\u001b[0m, in \u001b[0;36mGenerateSchema._dataclass_schema\u001b[0;34m(self, dataclass, origin)\u001b[0m\n\u001b[1;32m   1616\u001b[0m decorators \u001b[38;5;241m=\u001b[39m dataclass\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__pydantic_decorators__\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m DecoratorInfos\u001b[38;5;241m.\u001b[39mbuild(dataclass)\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;66;03m# Move kw_only=False args to the start of the list, as this is how vanilla dataclasses work.\u001b[39;00m\n\u001b[1;32m   1618\u001b[0m \u001b[38;5;66;03m# Note that when kw_only is missing or None, it is treated as equivalent to kw_only=True\u001b[39;00m\n\u001b[0;32m-> 1619\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1620\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_dc_field_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecorators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkw_only\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1622\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1623\u001b[0m has_post_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mhasattr\u001b[39m(dataclass, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__post_init__\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1624\u001b[0m has_slots \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mhasattr\u001b[39m(dataclass, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__slots__\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:1620\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1616\u001b[0m decorators \u001b[38;5;241m=\u001b[39m dataclass\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__pydantic_decorators__\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m DecoratorInfos\u001b[38;5;241m.\u001b[39mbuild(dataclass)\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;66;03m# Move kw_only=False args to the start of the list, as this is how vanilla dataclasses work.\u001b[39;00m\n\u001b[1;32m   1618\u001b[0m \u001b[38;5;66;03m# Note that when kw_only is missing or None, it is treated as equivalent to kw_only=True\u001b[39;00m\n\u001b[1;32m   1619\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\n\u001b[0;32m-> 1620\u001b[0m     (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_dc_field_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecorators\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m fields\u001b[38;5;241m.\u001b[39mitems()),\n\u001b[1;32m   1621\u001b[0m     key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m a: a\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkw_only\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1622\u001b[0m )\n\u001b[1;32m   1623\u001b[0m has_post_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mhasattr\u001b[39m(dataclass, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__post_init__\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1624\u001b[0m has_slots \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mhasattr\u001b[39m(dataclass, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__slots__\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:964\u001b[0m, in \u001b[0;36mGenerateSchema._generate_dc_field_schema\u001b[0;34m(self, name, field_info, decorators)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_dc_field_schema\u001b[39m(\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    959\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    960\u001b[0m     field_info: FieldInfo,\n\u001b[1;32m    961\u001b[0m     decorators: DecoratorInfos,\n\u001b[1;32m    962\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m core_schema\u001b[38;5;241m.\u001b[39mDataclassField:\n\u001b[1;32m    963\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prepare a DataclassField to represent the parameter/field, of a dataclass.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 964\u001b[0m     common_field \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_common_field_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfield_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecorators\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m core_schema\u001b[38;5;241m.\u001b[39mdataclass_field(\n\u001b[1;32m    966\u001b[0m         name,\n\u001b[1;32m    967\u001b[0m         common_field[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mschema\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    975\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mcommon_field[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    976\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:1134\u001b[0m, in \u001b[0;36mGenerateSchema._common_field_schema\u001b[0;34m(self, name, field_info, decorators)\u001b[0m\n\u001b[1;32m   1132\u001b[0m         schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_annotations(source_type, annotations, transform_inner_schema\u001b[38;5;241m=\u001b[39mset_discriminator)\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m         schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_annotations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[43m            \u001b[49m\u001b[43msource_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[43m            \u001b[49m\u001b[43mannotations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;66;03m# This V1 compatibility shim should eventually be removed\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;66;03m# push down any `each_item=True` validators\u001b[39;00m\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;66;03m# note that this won't work for any Annotated types that get wrapped by a function validator\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;66;03m# but that's okay because that didn't exist in V1\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m this_field_validators \u001b[38;5;241m=\u001b[39m filter_field_decorator_info_by_field(decorators\u001b[38;5;241m.\u001b[39mvalidators\u001b[38;5;241m.\u001b[39mvalues(), name)\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:1890\u001b[0m, in \u001b[0;36mGenerateSchema._apply_annotations\u001b[0;34m(self, source_type, annotations, transform_inner_schema)\u001b[0m\n\u001b[1;32m   1885\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1886\u001b[0m     get_inner_schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_wrapped_inner_schema(\n\u001b[1;32m   1887\u001b[0m         get_inner_schema, annotation, pydantic_js_annotation_functions\n\u001b[1;32m   1888\u001b[0m     )\n\u001b[0;32m-> 1890\u001b[0m schema \u001b[38;5;241m=\u001b[39m \u001b[43mget_inner_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pydantic_js_annotation_functions:\n\u001b[1;32m   1892\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m CoreMetadataHandler(schema)\u001b[38;5;241m.\u001b[39mmetadata\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_schema_generation_shared.py:83\u001b[0m, in \u001b[0;36mCallbackGetCoreSchemaHandler.__call__\u001b[0;34m(self, source_type)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, source_type: Any, \u001b[38;5;241m/\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m core_schema\u001b[38;5;241m.\u001b[39mCoreSchema:\n\u001b[0;32m---> 83\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     ref \u001b[38;5;241m=\u001b[39m schema\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mref\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ref_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto-def\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:1871\u001b[0m, in \u001b[0;36mGenerateSchema._apply_annotations.<locals>.inner_handler\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1869\u001b[0m from_property \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_schema_from_property(obj, source_type)\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_property \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1871\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_schema_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1872\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1873\u001b[0m     schema \u001b[38;5;241m=\u001b[39m from_property\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:789\u001b[0m, in \u001b[0;36mGenerateSchema._generate_schema_inner\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, PydanticRecursiveRef):\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m core_schema\u001b[38;5;241m.\u001b[39mdefinition_reference_schema(schema_ref\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mtype_ref)\n\u001b[0;32m--> 789\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:871\u001b[0m, in \u001b[0;36mGenerateSchema.match_type\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    869\u001b[0m origin \u001b[38;5;241m=\u001b[39m get_origin(obj)\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m origin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 871\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_match_generic_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arbitrary_types:\n\u001b[1;32m    874\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arbitrary_type_schema(obj)\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:895\u001b[0m, in \u001b[0;36mGenerateSchema._match_generic_type\u001b[0;34m(self, obj, origin)\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m from_property\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _typing_extra\u001b[38;5;241m.\u001b[39morigin_is_union(origin):\n\u001b[0;32m--> 895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_union_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m origin \u001b[38;5;129;01min\u001b[39;00m TUPLE_TYPES:\n\u001b[1;32m    897\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tuple_schema(obj)\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:1207\u001b[0m, in \u001b[0;36mGenerateSchema._union_schema\u001b[0;34m(self, union_type)\u001b[0m\n\u001b[1;32m   1205\u001b[0m         nullable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1206\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1207\u001b[0m         choices\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(choices) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1210\u001b[0m     s \u001b[38;5;241m=\u001b[39m choices[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:512\u001b[0m, in \u001b[0;36mGenerateSchema.generate_schema\u001b[0;34m(self, obj, from_dunder_get_core_schema)\u001b[0m\n\u001b[1;32m    509\u001b[0m         schema \u001b[38;5;241m=\u001b[39m from_property\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 512\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_schema_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    514\u001b[0m metadata_js_function \u001b[38;5;241m=\u001b[39m _extract_get_pydantic_json_schema(obj, schema)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadata_js_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:789\u001b[0m, in \u001b[0;36mGenerateSchema._generate_schema_inner\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, PydanticRecursiveRef):\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m core_schema\u001b[38;5;241m.\u001b[39mdefinition_reference_schema(schema_ref\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mtype_ref)\n\u001b[0;32m--> 789\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:875\u001b[0m, in \u001b[0;36mGenerateSchema.match_type\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arbitrary_types:\n\u001b[1;32m    874\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arbitrary_type_schema(obj)\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unknown_type_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:415\u001b[0m, in \u001b[0;36mGenerateSchema._unknown_type_schema\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_unknown_type_schema\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CoreSchema:\n\u001b[0;32m--> 415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticSchemaGenerationError(\n\u001b[1;32m    416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnable to generate pydantic-core schema for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    417\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSet `arbitrary_types_allowed=True` in the model_config to ignore this error\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or implement `__get_pydantic_core_schema__` on your type to fully support it.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf you got this error by calling handler(<some type>) within\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    420\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m `__get_pydantic_core_schema__` then you likely need to call\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    421\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m `handler.generate_schema(<some type>)` since we do not call\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    422\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m `__get_pydantic_core_schema__` on `<some type>` otherwise to avoid infinite recursion.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    423\u001b[0m     )\n",
      "\u001b[0;31mPydanticSchemaGenerationError\u001b[0m: Unable to generate pydantic-core schema for <class 'pandas.core.frame.DataFrame'>. Set `arbitrary_types_allowed=True` in the model_config to ignore this error or implement `__get_pydantic_core_schema__` on your type to fully support it.\n\nIf you got this error by calling handler(<some type>) within `__get_pydantic_core_schema__` then you likely need to call `handler.generate_schema(<some type>)` since we do not call `__get_pydantic_core_schema__` on `<some type>` otherwise to avoid infinite recursion.\n\nFor further information visit https://errors.pydantic.dev/2.8/u/schema-for-unknown-type"
     ]
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.document_stores.types import DuplicatePolicy\n",
    "from haystack.components.builders.prompt_builder import PromptBuilder\n",
    "from haystack_integrations.components.generators.ollama import OllamaGenerator\n",
    "from haystack_integrations.components.retrievers.qdrant import QdrantEmbeddingRetriever\n",
    "from haystack_integrations.document_stores.qdrant import QdrantDocumentStore\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder, SentenceTransformersDocumentEmbedder\n",
    "from haystack import Document\n",
    "\n",
    "# Function to read text file\n",
    "def read_text_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {file_path} was not found. Please make sure the file exists and the path is correct.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the file: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Read the text file\n",
    "file_path = \"1.PMAY-U 2.0 FAQ.txt\"  # Assuming you've converted the .docx to .txt\n",
    "document_content = read_text_file(file_path)\n",
    "\n",
    "if document_content is None:\n",
    "    print(\"Exiting due to file read error.\")\n",
    "    exit(1)\n",
    "\n",
    "# Initialize QdrantDocumentStore\n",
    "document_store = QdrantDocumentStore(\n",
    "    url='http://localhost:6333',\n",
    "    recreate_index=True,\n",
    "    return_embedding=True,\n",
    "    wait_result_from_api=True,\n",
    ")\n",
    "\n",
    "# Create a Document object\n",
    "document = Document(content=document_content)\n",
    "\n",
    "# Initialize and use SentenceTransformersDocumentEmbedder\n",
    "document_embedder = SentenceTransformersDocumentEmbedder()\n",
    "document_embedder.warm_up()\n",
    "documents_with_embeddings = document_embedder.run([document])\n",
    "\n",
    "# Write document to the document store\n",
    "document_store.write_documents(documents_with_embeddings.get(\"documents\"), policy=DuplicatePolicy.OVERWRITE)\n",
    "\n",
    "# Initialize QdrantEmbeddingRetriever\n",
    "retriever = QdrantEmbeddingRetriever(document_store=document_store)\n",
    "\n",
    "# Define the prompt template\n",
    "template = \"\"\"\n",
    "Given only the following information from the PMAY-U 2.0 FAQ document, answer the question.\n",
    "Ignore your own knowledge.\n",
    "Context:\n",
    "{% for document in documents %}\n",
    " {{ document.content }}\n",
    "{% endfor %}\n",
    "Question: {{ query }}\n",
    "\"\"\"\n",
    "\n",
    "# Set up the pipeline\n",
    "pipe = Pipeline()\n",
    "pipe.add_component(\"text_embedder\", SentenceTransformersTextEmbedder())\n",
    "pipe.add_component(\"retriever\", retriever)\n",
    "pipe.add_component(\"prompt_builder\", PromptBuilder(template=template))\n",
    "pipe.add_component(\"llm\", OllamaGenerator(model=\"llama3\", url=\"http://localhost:6333/api/generate\"))\n",
    "pipe.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
    "pipe.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "pipe.connect(\"prompt_builder\", \"llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 23.92it/s]\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "404 Client Error: Not Found for url: http://localhost:6333/api/generate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example query\u001b[39;00m\n\u001b[1;32m      2\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow Central Assistance will be released for Private Sector AHP Projects ?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_builder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext_embedder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplies\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env3.8/lib/python3.8/site-packages/haystack/core/pipeline/pipeline.py:233\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, data, debug, include_outputs_from)\u001b[0m\n\u001b[1;32m    230\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaximum loops count (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_loops_allowed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exceeded for component \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PipelineMaxLoops(msg)\n\u001b[0;32m--> 233\u001b[0m res: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_component\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponents_inputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m include_outputs_from:\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;66;03m# Deepcopy the outputs to prevent downstream nodes from modifying them\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;66;03m# We don't care about loops - Always store the last output.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     extra_outputs[name] \u001b[38;5;241m=\u001b[39m deepcopy(res)\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env3.8/lib/python3.8/site-packages/haystack/core/pipeline/pipeline.py:67\u001b[0m, in \u001b[0;36mPipeline._run_component\u001b[0;34m(self, name, inputs)\u001b[0m\n\u001b[1;32m     65\u001b[0m span\u001b[38;5;241m.\u001b[39mset_content_tag(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaystack.component.input\u001b[39m\u001b[38;5;124m\"\u001b[39m, inputs)\n\u001b[1;32m     66\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning component \u001b[39m\u001b[38;5;132;01m{component_name}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, component_name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m---> 67\u001b[0m res: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mnodes[name][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisits\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# After a Component that has variadic inputs is run, we need to reset the variadic inputs that were consumed\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env3.8/lib/python3.8/site-packages/haystack_integrations/components/generators/ollama/generator.py:198\u001b[0m, in \u001b[0;36mOllamaGenerator.run\u001b[0;34m(self, prompt, generation_kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl, json\u001b[38;5;241m=\u001b[39mjson_payload, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout, stream\u001b[38;5;241m=\u001b[39mstream)\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# throw error on unsuccessful response\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    201\u001b[0m     chunks: List[StreamingChunk] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_streaming_response(response)\n",
      "File \u001b[0;32m~/Documents/ChatBot/Llama3/new_env3.8/lib/python3.8/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: http://localhost:6333/api/generate"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "query = \"How Central Assistance will be released for Private Sector AHP Projects ?\"\n",
    "response = pipe.run({\"prompt_builder\": {\"query\": query}, \"text_embedder\": {\"text\": query}})\n",
    "print(response[\"llm\"][\"replies\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
